{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imports",
   "id": "d1a318f8bca08acd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:05:18.476711Z",
     "start_time": "2025-04-27T12:05:14.237226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomRotation\n"
   ],
   "id": "dac772af76a78bc1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train-Test-Val Split",
   "id": "915fbe3bafda22e0"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "dataset_directory = \"../Dataset Generation/dataset\"\n",
    "\n",
    "# Image and label directory arrays\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for recipe_folder in os.listdir(dataset_directory):\n",
    "    recipe_path = os.path.join(dataset_directory, recipe_folder)\n",
    "    allergens_file = os.path.join(recipe_path, 'allergens.json')\n",
    "\n",
    "    if os.path.isfile(allergens_file):\n",
    "        with open(allergens_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            allergens = data['allergens']\n",
    "\n",
    "            for image in data['images']:\n",
    "                images.append(os.path.join(dataset_directory, recipe_folder, image))\n",
    "                labels.append(allergens)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = np.array(images).reshape(-1,1) # iterative_train_test_split expects 2d array\n",
    "y = np.array(labels)"
   ],
   "id": "61a7e57ddb6e4ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "zeros_per_label = np.sum(y == 0, axis=0).tolist()\n",
    "ones_per_label = np.sum(y == 1, axis=0).tolist()\n",
    "print(\"Number of 0s for each label:\")\n",
    "print(zeros_per_label)\n",
    "print(\"Number of 1s for each label\")\n",
    "print(ones_per_label)"
   ],
   "id": "301ba2834491f6c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_train, y_train, x_temp, y_temp = iterative_train_test_split(x, y, test_size=0.3) # http://scikit.ml/stratification.html",
   "id": "e0b1141d75a591e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_test, y_test, x_val, y_val = iterative_train_test_split(x_temp, y_temp, test_size=0.5)",
   "id": "fdcd7562614b031b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape)",
   "id": "d7cac7ad7a637d8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_train, y_train, x_test, y_test, x_val, y_val",
   "id": "f7847d37bef5d738",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "zeros_per_label = np.sum(y_train == 0, axis=0).tolist()\n",
    "ones_per_label = np.sum(y_train == 1, axis=0).tolist()\n",
    "print(\"Number of 0s for each label:\")\n",
    "print(zeros_per_label)\n",
    "print(\"Number of 1s for each label\")\n",
    "print(ones_per_label)"
   ],
   "id": "6ff41a0f1660dd36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "zeros_per_label = np.sum(y_test == 0, axis=0).tolist()\n",
    "ones_per_label = np.sum(y_test == 1, axis=0).tolist()\n",
    "print(\"Number of 0s for each label:\")\n",
    "print(zeros_per_label)\n",
    "print(\"Number of 1s for each label\")\n",
    "print(ones_per_label)"
   ],
   "id": "3060495c703bc88f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "zeros_per_label = np.sum(y_val == 0, axis=0).tolist()\n",
    "ones_per_label = np.sum(y_val == 1, axis=0).tolist()\n",
    "print(\"Number of 0s for each label:\")\n",
    "print(zeros_per_label)\n",
    "print(\"Number of 1s for each label\")\n",
    "print(ones_per_label)"
   ],
   "id": "e3a4e7e999eb12ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hyperparameters",
   "id": "2a7dbf1946809fb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "learning_rate = 1e-5\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "prediction_threshold = 0.5"
   ],
   "id": "12d0317a88d1f61c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset Loader",
   "id": "647813a33dfee08e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset loader class shell: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "\n",
    "class FoodAllergenDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, target_transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB') # Convert all images to 3 channel RGB as dataset contains some 4 channel RGBA images\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label"
   ],
   "id": "6d2422efba98f9d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Transform images to tensors and resize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "# Test more transforms later in training to improve accuracy - cropping, rotation, centering, flipping etc."
   ],
   "id": "24ad361314230744",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = FoodAllergenDataset(x_train, y_train, transform=transform)\n",
    "val_dataset = FoodAllergenDataset(x_val, y_val, transform=transform)\n",
    "test_dataset = FoodAllergenDataset(x_test, y_test, transform=transform)"
   ],
   "id": "29ce8f822bf53b9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Train Test Val DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "a634e8bae52e47de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set Accelerator Device",
   "id": "66d21ea99f39807d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:05:22.479617Z",
     "start_time": "2025-04-27T12:05:22.451640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ],
   "id": "fb004ca30e8d4469",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CNN Model Architecture",
   "id": "65f72ad59ca15e88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sample CNN model from pytorch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_labels=14):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ],
   "id": "a56da85cb28a203a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 14) # Add final fully connected layer with 14 outputs"
   ],
   "id": "46c69f65d1f6b7ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#model = Net().to(device)\n",
    "model = resnet.to(device)\n",
    "print(model)"
   ],
   "id": "7666837134ef8417",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loss Function and Optimizer",
   "id": "baaf8f642ecf12c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "2399c463c56d6b4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training Loop",
   "id": "9a30f85c07bdbfb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "def train_one_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        prediction = model(images)\n",
    "        loss = loss_fn(prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # Accumulate loss for this batch\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            current = batch * len(images)\n",
    "            print(f\"loss: {loss.item():.7f} [{current:5d}/{size:5d}]\")\n",
    "\n",
    "    # Return average training loss for this epoch\n",
    "    return total_loss / len(dataloader)"
   ],
   "id": "a110414e40a8f7a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def validate_one_epoch(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            prediction = model(images)\n",
    "            loss = loss_fn(prediction, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(dataloader)\n",
    "    print(f\"Validation loss: {avg_val_loss:.7f}\")\n",
    "\n",
    "    # Return average validation loss for this epoch\n",
    "    return avg_val_loss"
   ],
   "id": "a0294699f123c2d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "https://www.geeksforgeeks.org/how-to-handle-overfitting-in-pytorch-models-using-early-stopping/\n",
    "\n",
    "patience: Number of epochs to wait before stopping if no improvement.\n",
    "delta: Minimum change in the monitored quantity to qualify as an improvement.\n",
    "best_score, best_model_state: Track the best validation score and model state.\n",
    "call method: Updates the early stopping logic.\n",
    "\"\"\"\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0"
   ],
   "id": "83bf43f5d17ec23a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "def save_model(epoch, model, optimizer, training_losses, validation_losses):\n",
    "    torch.save({\n",
    "        \"epoch\": epoch+1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"training_losses\": training_losses, # full loss history, so that post-checkpoint models will have correct loss graph\n",
    "        \"validation_losses\": validation_losses\n",
    "    }, \"model.pt\")"
   ],
   "id": "ecd0df3168ec0d26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Store losses to be graphed\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "starting_epoch = 0"
   ],
   "id": "60973d08ab4632ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "# Only run if loading from checkpoint\n",
    "def load_model(model_path, model, optimizer):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    checkpoint_epoch = checkpoint[\"epoch\"]\n",
    "    training_losses = checkpoint[\"training_losses\"]\n",
    "    validation_losses = checkpoint[\"validation_losses\"]\n",
    "\n",
    "    return model, optimizer, checkpoint_epoch, training_losses, validation_losses"
   ],
   "id": "520207abc052e249",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Run if continuing training from a checkpoint\n",
    "# model, optimizer, starting_epoch, training_losses, validation_losses = load_model(\"model.pt\", model, optimizer)"
   ],
   "id": "d7902a9c2e65349b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run training and validation loops\n",
    "best_val_loss = 1_000_000.\n",
    "early_stopping = EarlyStopping(patience=5, delta=0.05)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    # Train and validate this epoch\n",
    "    train_loss = train_one_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "    val_loss = validate_one_epoch(val_dataloader, model, loss_fn)\n",
    "\n",
    "    # Append losses for this epoch\n",
    "    training_losses.append(train_loss)\n",
    "    validation_losses.append(val_loss)\n",
    "\n",
    "    # Save model checkpoint if validation loss improves\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.7f} to {val_loss:.7f}\")\n",
    "        best_val_loss = val_loss\n",
    "        save_model(epoch, model, optimizer, training_losses, validation_losses)\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "print(f\"Training Complete\")"
   ],
   "id": "bdc320a832dd3821",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Evaluation",
   "id": "a51156670d7b0912"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load losses and epochs from saved model\n",
    "model, optimizer, epochs, training_losses, validation_losses = load_model(\"model.pt\", model, optimizer)\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, epochs + 1), training_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "8891fdd79b6dae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        outputLogits = model(images)\n",
    "        outputs = torch.sigmoid(outputLogits)\n",
    "        print(outputs)"
   ],
   "id": "345699642d5c6dcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ALLERGENS = [\n",
    "    \"Cereals containing gluten\", \"Crustaceans\", \"Eggs\", \"Fish\",\n",
    "    \"Peanuts\", \"Soybeans\", \"Milk\", \"Nuts\", \"Celery\", \"Mustard\",\n",
    "    \"Sesame seeds\",  \"Sulphur dioxide and sulphites\", \"Lupin\", \"Molluscs\"\n",
    "]"
   ],
   "id": "ea731c92c5d4d1f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrices(matrices):\n",
    "    # Plot matrices on seaborn\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        sns.heatmap(\n",
    "            matrix,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Reds\",\n",
    "            cbar=False,\n",
    "            xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "            yticklabels=[\"True 0\", \"True 1\"]\n",
    "        )\n",
    "        plt.title(f\"Confusion Matrix: {ALLERGENS[i]}\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "id": "f9d47de5ed6042a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "\n",
    "def test_loop(dataloader, model):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    all_predictions = []\n",
    "    all_actual = []\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputLogits = model(images)\n",
    "            probs = torch.sigmoid(outputLogits) # # Apply sigmoid to convert logits to get probabilities 0-1\n",
    "            preds = (probs > prediction_threshold).long() # Get binary predictions based on prediction threshold param\n",
    "\n",
    "            total += labels.numel()\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            all_predictions.append(preds.cpu().numpy())\n",
    "            all_actual.append(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Error: \\n Accuracy: {accuracy:.2f} % \\n\\n')\n",
    "\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_actual = np.concatenate(all_actual, axis=0)\n",
    "\n",
    "    matrices = multilabel_confusion_matrix(all_actual, all_predictions)\n",
    "    plot_confusion_matrices(matrices)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    # Sklearn classification report\n",
    "    report = classification_report(all_actual, all_predictions, target_names=ALLERGENS, zero_division=0)\n",
    "    print(report)"
   ],
   "id": "eba65702c8bb8728",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_loop(test_dataloader, model)",
   "id": "b44d3535fce8cb87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8f9024365918e7e0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
